{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID 19 Severity Prediction  \n",
    "**Goal**: For a given individual who is diagnosed with COVID 19 we want to determine the severity of their infection in terms of the probability of decease and probability of ICU admittance.  \n",
    "**Dataset**: The dataset available to us is curated by the Mexico Government and contains information for 500k+ observations. It contains information regarding the result of the test, time of detection, demographic information and most importantly that of various health conditions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566602, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>patient_type</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>date_symptoms</th>\n",
       "      <th>date_died</th>\n",
       "      <th>intubed</th>\n",
       "      <th>pneumonia</th>\n",
       "      <th>age</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>...</th>\n",
       "      <th>inmsupr</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>other_disease</th>\n",
       "      <th>cardiovascular</th>\n",
       "      <th>obesity</th>\n",
       "      <th>renal_chronic</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>contact_other_covid</th>\n",
       "      <th>covid_res</th>\n",
       "      <th>icu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16169f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>04-05-2020</td>\n",
       "      <td>02-05-2020</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009bf</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b5948</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17-04-2020</td>\n",
       "      <td>10-04-2020</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d01b5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>22-04-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sex  patient_type  entry_date date_symptoms   date_died  intubed  \\\n",
       "0  16169f    2             1  04-05-2020    02-05-2020  9999-99-99       97   \n",
       "1  1009bf    2             1  19-03-2020    17-03-2020  9999-99-99       97   \n",
       "2  167386    1             2  06-04-2020    01-04-2020  9999-99-99        2   \n",
       "3  0b5948    2             2  17-04-2020    10-04-2020  9999-99-99        2   \n",
       "4  0d01b5    1             2  13-04-2020    13-04-2020  22-04-2020        2   \n",
       "\n",
       "   pneumonia  age  pregnancy  ...  inmsupr  hypertension  other_disease  \\\n",
       "0          2   27         97  ...        2             2              2   \n",
       "1          2   24         97  ...        2             2              2   \n",
       "2          2   54          2  ...        2             2              2   \n",
       "3          1   30         97  ...        2             2              2   \n",
       "4          2   60          2  ...        2             1              2   \n",
       "\n",
       "   cardiovascular  obesity  renal_chronic  tobacco  contact_other_covid  \\\n",
       "0               2        2              2        2                    2   \n",
       "1               2        2              2        2                   99   \n",
       "2               2        1              2        2                   99   \n",
       "3               2        2              2        2                   99   \n",
       "4               1        2              2        2                   99   \n",
       "\n",
       "   covid_res  icu  \n",
       "0          1   97  \n",
       "1          1   97  \n",
       "2          1    2  \n",
       "3          1    2  \n",
       "4          1    2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and asses dataset\n",
    "# Dataset description can be found at: https://www.kaggle.com/tanmoyx/covid19-patient-precondition-dataset?select=covid.csv\n",
    "df = pd.read_csv(\"../data/mexico_government_covid19_patient/covid.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the date_died is invalid then the given case of COVID 19 did not result in fatality. So we form a new feature \"lethal\" indicating this. All invalid dates are replaced with no(2), and all valid dates are replaced with 1(yes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>patient_type</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>date_symptoms</th>\n",
       "      <th>lethal</th>\n",
       "      <th>intubed</th>\n",
       "      <th>pneumonia</th>\n",
       "      <th>age</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>...</th>\n",
       "      <th>inmsupr</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>other_disease</th>\n",
       "      <th>cardiovascular</th>\n",
       "      <th>obesity</th>\n",
       "      <th>renal_chronic</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>contact_other_covid</th>\n",
       "      <th>covid_res</th>\n",
       "      <th>icu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16169f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>04-05-2020</td>\n",
       "      <td>02-05-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009bf</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b5948</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17-04-2020</td>\n",
       "      <td>10-04-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d01b5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sex  patient_type  entry_date date_symptoms lethal  intubed  \\\n",
       "0  16169f    2             1  04-05-2020    02-05-2020      2       97   \n",
       "1  1009bf    2             1  19-03-2020    17-03-2020      2       97   \n",
       "2  167386    1             2  06-04-2020    01-04-2020      2        2   \n",
       "3  0b5948    2             2  17-04-2020    10-04-2020      2        2   \n",
       "4  0d01b5    1             2  13-04-2020    13-04-2020      1        2   \n",
       "\n",
       "   pneumonia  age  pregnancy  ...  inmsupr  hypertension  other_disease  \\\n",
       "0          2   27         97  ...        2             2              2   \n",
       "1          2   24         97  ...        2             2              2   \n",
       "2          2   54          2  ...        2             2              2   \n",
       "3          1   30         97  ...        2             2              2   \n",
       "4          2   60          2  ...        2             1              2   \n",
       "\n",
       "   cardiovascular  obesity  renal_chronic  tobacco  contact_other_covid  \\\n",
       "0               2        2              2        2                    2   \n",
       "1               2        2              2        2                   99   \n",
       "2               2        1              2        2                   99   \n",
       "3               2        2              2        2                   99   \n",
       "4               1        2              2        2                   99   \n",
       "\n",
       "   covid_res  icu  \n",
       "0          1   97  \n",
       "1          1   97  \n",
       "2          1    2  \n",
       "3          1    2  \n",
       "4          1    2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the data died column to indicate if patient death\n",
    "# If there is a valid date then patient death and represent as 1 otherwise represent as 2\n",
    "df['date_died'] = df['date_died'].replace(to_replace=\"9999-99-99\", value=2)\n",
    "df['date_died'] = df['date_died'].mask(df['date_died'].ne(2), 1)\n",
    "df = df.rename(columns={'date_died':'lethal'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features entry_date and date_symptoms provide valuable information, but by themselves they are not relevant to determining the severity of COVID 19. A more relevant feature would be the time between entry_date and data_symptoms. So we create a feature by subtracting these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>patient_type</th>\n",
       "      <th>lethal</th>\n",
       "      <th>intubed</th>\n",
       "      <th>pneumonia</th>\n",
       "      <th>age</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>copd</th>\n",
       "      <th>...</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>other_disease</th>\n",
       "      <th>cardiovascular</th>\n",
       "      <th>obesity</th>\n",
       "      <th>renal_chronic</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>contact_other_covid</th>\n",
       "      <th>covid_res</th>\n",
       "      <th>icu</th>\n",
       "      <th>days_to_medical_help</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16169f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009bf</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b5948</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d01b5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sex  patient_type lethal  intubed  pneumonia  age  pregnancy  \\\n",
       "0  16169f    2             1      2       97          2   27         97   \n",
       "1  1009bf    2             1      2       97          2   24         97   \n",
       "2  167386    1             2      2        2          2   54          2   \n",
       "3  0b5948    2             2      2        2          1   30         97   \n",
       "4  0d01b5    1             2      1        2          2   60          2   \n",
       "\n",
       "   diabetes  copd  ...  hypertension  other_disease  cardiovascular  obesity  \\\n",
       "0         2     2  ...             2              2               2        2   \n",
       "1         2     2  ...             2              2               2        2   \n",
       "2         2     2  ...             2              2               2        1   \n",
       "3         2     2  ...             2              2               2        2   \n",
       "4         1     2  ...             1              2               1        2   \n",
       "\n",
       "   renal_chronic  tobacco  contact_other_covid  covid_res  icu  \\\n",
       "0              2        2                    2          1   97   \n",
       "1              2        2                   99          1   97   \n",
       "2              2        2                   99          1    2   \n",
       "3              2        2                   99          1    2   \n",
       "4              2        2                   99          1    2   \n",
       "\n",
       "   days_to_medical_help  \n",
       "0                     2  \n",
       "1                     2  \n",
       "2                     5  \n",
       "3                     7  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With date_symptoms and entry_date we can calculate time between disease contraction and medical attention\n",
    "# This would be a more relevant feature to use rather than just the dates\n",
    "df['days_to_medical_help'] = (pd.to_datetime(df['entry_date'], dayfirst=True) - pd.to_datetime(df['date_symptoms'], dayfirst=True)).dt.days\n",
    "df = df.drop(columns=['entry_date', 'date_symptoms'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Patient ID from the dataset since it won't help in predictions\n",
    "columns_to_drop = ['id']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                      int64\n",
       "patient_type             int64\n",
       "lethal                  object\n",
       "intubed                  int64\n",
       "pneumonia                int64\n",
       "age                      int64\n",
       "pregnancy                int64\n",
       "diabetes                 int64\n",
       "copd                     int64\n",
       "asthma                   int64\n",
       "inmsupr                  int64\n",
       "hypertension             int64\n",
       "other_disease            int64\n",
       "cardiovascular           int64\n",
       "obesity                  int64\n",
       "renal_chronic            int64\n",
       "tobacco                  int64\n",
       "contact_other_covid      int64\n",
       "covid_res                int64\n",
       "icu                      int64\n",
       "days_to_medical_help     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types of all features\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now even though we know that most of these variables are categorical pandas has encoded them as int or floats so we must convert them to categorical. We also would want to normalize all non-categorical variables and replace missing values encoded as 97, 98, and 99 in the categorical variable. We also change the encoding from 2 -> No to 0 -> to No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since most categorical features are currently int64 change them to categorical\n",
    "# We also want to normalize all non categorical features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "categorical_columns = ['sex', 'patient_type',\n",
    "       'intubed', 'pneumonia', 'pregnancy', 'diabetes', 'copd',\n",
    "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
    "       'obesity', 'renal_chronic', 'tobacco', 'contact_other_covid',\n",
    "       'covid_res', 'icu', 'lethal']\n",
    "# The dataset indicates that missing values are 97, 98, 99 so we replace them with -1 for uniformity\n",
    "df = df.fillna(value=-1)\n",
    "for column in df.columns:\n",
    "    if column in categorical_columns:\n",
    "        # Change no encoding from 2 to 0\n",
    "        df[column] = df[column].replace(to_replace=2, value=0)\n",
    "        # Replace all missing values with -1\n",
    "        df[column] = df[column].replace(to_replace=[97, 98, 99], value=-1).astype('category')\n",
    "    else:\n",
    "        # Normalize non categorical features\n",
    "        df[column] = MinMaxScaler().fit_transform(np.array(df[column]).reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220657, 21)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can only use observations in which the individual tested postive for COVID 19\n",
    "covid_cases = df[df['covid_res'] == 1]\n",
    "covid_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66910, 21)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding of 3 for 'covid_res' is supposed to be awaiting results so we can use these as the prediction set for risk assesment\n",
    "awaiting_cases = df[df['covid_res'] == 3]\n",
    "awaiting_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store the outcomes and features\n",
    "# We could try combining icu and death\n",
    "# However we do not want to include either in the prediction for the other due to expected high dependency\n",
    "features = ['sex', 'patient_type', 'age', 'days_to_medical_help',\n",
    "       'intubed', 'pneumonia', 'pregnancy', 'diabetes', 'copd',\n",
    "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
    "       'obesity', 'renal_chronic', 'tobacco']\n",
    "outcomes = ['icu', 'death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICU Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68210, 21)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we train a model to predict 'icu' for that we form a dataset of known icu cases i.e Yes or No so we remove 0s which were\n",
    "# supposed to be missing values or cases in which we do not know if the individual was in the icu\n",
    "current_outcome = outcomes[0] # i.e 'icu'\n",
    "icu_res_known = covid_cases[covid_cases['icu'] != -1]\n",
    "icu_res_known.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(icu_res_known, shuffle=True, test_size=0.3, stratify=icu_res_known['icu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='icu', ylabel='count'>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before we train we want to check the distribution of icu in the train set to ensure proper training\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x='icu', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above graph indicates that the data is highly biased so we must perform some sampling to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "# Over Sample the Minority Label to be 0.3 in proportion\n",
    "over = SMOTE(sampling_strategy=0.3)\n",
    "# Down Sample the Majority Label so that there are twice as many as minority\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# Pipeline to combine \n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# Sampled data\n",
    "obs, results = pipeline.fit_resample(train[features], train['icu'])\n",
    "obs = obs.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26202, 13101)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if sampling has given the desired results\n",
    "len(results[results == 0]), len(results[results == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9071494893221913\n",
      "Precision: [0.95606422 0.4622595 ]\n",
      "Recall: [0.94176106 0.53634803]\n",
      "F-Score: [0.94885874 0.49655538]\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest as a baseline model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "rf = RandomForestClassifier(n_estimators=40, max_depth=10).fit(obs, results)\n",
    "print(\"Accuracy: {}\".format(rf.score(test[features], test['icu'])))\n",
    "metrics = precision_recall_fscore_support(test['icu'], rf.predict(test[features]))\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal Data Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9170209646679373\n",
      "Precision: [0.92660182 0.54738878]\n",
      "Recall: [0.98749733 0.16199199]\n",
      "F-Score: [0.95608091 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "# Let us test for the non sampled dataset\n",
    "rf_normal = RandomForestClassifier(n_estimators=40, max_depth=10).fit(train[features], train['icu'])\n",
    "print(\"Accuracy: {}\".format(rf_normal.score(test[features], test['icu'])))\n",
    "metrics_normal = precision_recall_fscore_support(test['icu'], rf_normal.predict(test[features]))\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics_normal[0], metrics_normal[1], metrics_normal[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE & Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets repeat the procedure for \"death\" risk prediciton but with a function since that might help with the API implementation\n",
    "def checkBinaryBalance(data, features, output, negative_label=0, positive_label=1):\n",
    "    data_arr = np.array(data[output])\n",
    "    if abs(data_arr[data_arr == negative_label]. shape[0] / len(data) - data_arr[data_arr == positive_label].shape[0] / len(data_arr)) > 0.4:\n",
    "        print(\"Not Balanced returning sampled dataet.\")\n",
    "        # Over Sample the Minority Label to be 0.3 in proportion\n",
    "        over = SMOTE(sampling_strategy=0.3)\n",
    "        # Down Sample the Majority Label so that there are twice as many as minority\n",
    "        under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "        # Pipeline to combine \n",
    "        steps = [('o', over), ('u', under)]\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        # Sampled data\n",
    "        obs, results = pipeline.fit_resample(data[features], data_arr)\n",
    "        obs = obs.fillna(0)\n",
    "        return obs, results\n",
    "    print(\"Balanced dataset returning original.\")\n",
    "    obs = data[features]\n",
    "    results = data_arr\n",
    "    return obs, results\n",
    "\n",
    "def randomForestEvaluation(obs, results, test_obs, test_results):\n",
    "    rf = RandomForestClassifier(n_estimators=40, max_depth=10).fit(obs, results)\n",
    "    print(\"Accuracy: {}\".format(rf.score(test_obs, test_results)))\n",
    "    metrics = precision_recall_fscore_support(test_results, rf.predict(test_obs))\n",
    "    print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All sklearn-models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have trained on Random Forest Let us test the baselines for all classifiers within the sklearn library\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    #KNeighborsClassifier(2),\n",
    "    #SVC(kernel=\"linear\", C=0.025),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=20),\n",
    "    MLPClassifier(max_iter=10000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    #QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "\"\"\"names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\"\"\"\n",
    "names = [\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "def allModelEvaluation(names, classifiers, obs, results, test_obs, test_results):\n",
    "    scores = {}\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(\"Training \" + name)\n",
    "        clf.fit(obs, results)\n",
    "        train_score =  clf.score(obs, results)\n",
    "        metrics_train = precision_recall_fscore_support(results, clf.predict(obs))\n",
    "        test_score = clf.score(test_obs, test_results)\n",
    "        metrics_test = precision_recall_fscore_support(test_results, clf.predict(test_obs))\n",
    "        print(\"Train Accuracy: {}\".format(train_score))\n",
    "        print(\"Train Precision: {}\\nTrain Recall: {}\\nTrain F-Score: {}\\n\".format(metrics_train[0], metrics_train[1], metrics_train[2]))\n",
    "        print(\"Test Accuracy: {}\".format(test_score))\n",
    "        print(\"Test Precision: {}\\nTest Recall: {}\\nTest F-Score: {}\".format(metrics_test[0], metrics_test[1], metrics_test[2]))\n",
    "        scores[name] = {'test accuracy' : test_score, 'test precision' : metrics_test[0], 'test recall': metrics_test[1], 'train accuracy' : train_score, 'train precision' : metrics_train[0], 'train recall' : metrics_train[1]}\n",
    "        print(\"-----------\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Balanced returning sampled dataet.\n",
      "Training Decision Tree\n",
      "Train Accuracy: 0.9692135460397425\n",
      "Train Precision: [0.96168625 0.98586255]\n",
      "Train Recall: [0.99339745 0.92084574]\n",
      "Train F-Score: [0.97728467 0.95224564]\n",
      "\n",
      "Test Accuracy: 0.8699115476714069\n",
      "Test Precision: [0.93868182 0.2886836 ]\n",
      "Test Recall: [0.91771746 0.35775615]\n",
      "Test F-Score: [0.92808127 0.31952965]\n",
      "-----------\n",
      "Training Random Forest\n",
      "Train Accuracy: 0.9669999745566497\n",
      "Train Precision: [0.96629845 0.96848706]\n",
      "Train Recall: [0.98484848 0.93130295]\n",
      "Train F-Score: [0.97548529 0.94953111]\n",
      "\n",
      "Test Accuracy: 0.8835459121340957\n",
      "Test Precision: [0.94506513 0.34957427]\n",
      "Test Recall: [0.92653345 0.42301088]\n",
      "Test F-Score: [0.93570754 0.38280238]\n",
      "-----------\n",
      "Training Neural Net\n",
      "Train Accuracy: 0.8166297738086151\n",
      "Train Precision: [0.81273667 0.82986344]\n",
      "Train Recall: [0.94198916 0.565911  ]\n",
      "Train F-Score: [0.87260257 0.67292943]\n",
      "\n",
      "Test Accuracy: 0.9105214289204906\n",
      "Test Precision: [0.95786106 0.47924901]\n",
      "Test Recall: [0.94368455 0.55523755]\n",
      "Test F-Score: [0.95071996 0.5144524 ]\n",
      "-----------\n",
      "Training AdaBoost\n",
      "Train Accuracy: 0.81291504465308\n",
      "Train Precision: [0.81057835 0.82083054]\n",
      "Train Recall: [0.93874513 0.56125487]\n",
      "Train F-Score: [0.86996658 0.66666667]\n",
      "\n",
      "Test Accuracy: 0.9122807017543859\n",
      "Test Precision: [0.95903641 0.48818898]\n",
      "Test Recall: [0.94443257 0.56783057]\n",
      "Test F-Score: [0.95167847 0.52500662]\n",
      "-----------\n",
      "Training Naive Bayes\n",
      "Train Accuracy: 0.8080808080808081\n",
      "Train Precision: [0.80242471 0.82872013]\n",
      "Train Recall: [0.94473704 0.53476834]\n",
      "Train F-Score: [0.86778496 0.65005799]\n",
      "\n",
      "Test Accuracy: 0.9154571665933636\n",
      "Test Precision: [0.9574491  0.50448076]\n",
      "Test Recall: [0.94977559 0.54779622]\n",
      "Test F-Score: [0.95359691 0.52524698]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models for \"icu\"\n",
    "# Form train test\n",
    "train, test = train_test_split(icu_res_known, shuffle=True, test_size=0.3, stratify=icu_res_known['icu'])\n",
    "# Check if the resutls are balanced and get obs, results which are balanced\n",
    "obs, results = checkBinaryBalance(train, features, 'icu', 0, 1)\n",
    "sampled_icu_scores = allModelEvaluation(names, classifiers, obs, results, test[features], test['icu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above results we can gauge that _____ is the best model. So let us try running hyperparemeter optimization on it\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "calibrated_forest = CalibratedClassifierCV(\n",
    "   base_estimator=RandomForestClassifier())\n",
    "param_grid = {\n",
    "   'base_estimator__max_depth': [20, 40, 60, 80, 100, 120],\n",
    "    'base_estimator__n_estimators': [10, 50, 100, 150, 200]}\n",
    "search = GridSearchCV(calibrated_forest, param_grid, cv=5)\n",
    "search.fit(obs, results)\n",
    "\n",
    "print(\"Accuracy: {}\".format(search.score(test[features], test['icu'])))\n",
    "metrics = precision_recall_fscore_support(test['icu'], search.predict(test[features]))\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras Fully-connected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Balanced returning sampled dataet.\n"
     ]
    }
   ],
   "source": [
    "# Let us now train on a Dense Model in Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Check if the resutls are balanced and get obs, results which are balanced\n",
    "obs, results = checkBinaryBalance(train, features, 'icu', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,777\n",
      "Trainable params: 3,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a Fully Connected Model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_dim=17))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpoints\n",
    "# Callback to Early Stop if Validation loss is not improving\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "# Callback to Keep storing best model\n",
    "mc = ModelCheckpoint(\"best.h5\", monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obs, validation_obs, test_res, validation_res = train_test_split(test[features], test['icu'], test_size=0.5, shuffle=True, stratify=test['icu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1215/1229 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.7984\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91654, saving model to best.h5\n",
      "1229/1229 [==============================] - 5s 4ms/step - loss: 0.4989 - accuracy: 0.7986 - val_loss: 0.3552 - val_accuracy: 0.9165\n",
      "Epoch 2/100\n",
      "1222/1229 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.8090\n",
      "Epoch 00002: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4797 - accuracy: 0.8093 - val_loss: 0.3297 - val_accuracy: 0.9164\n",
      "Epoch 3/100\n",
      "1219/1229 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.8092\n",
      "Epoch 00003: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4769 - accuracy: 0.8092 - val_loss: 0.3388 - val_accuracy: 0.9164\n",
      "Epoch 4/100\n",
      "1223/1229 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.8092\n",
      "Epoch 00004: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4742 - accuracy: 0.8092 - val_loss: 0.3338 - val_accuracy: 0.9162\n",
      "Epoch 5/100\n",
      "1225/1229 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.8103\n",
      "Epoch 00005: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4716 - accuracy: 0.8104 - val_loss: 0.3569 - val_accuracy: 0.9142\n",
      "Epoch 6/100\n",
      "1221/1229 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8111\n",
      "Epoch 00006: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4689 - accuracy: 0.8113 - val_loss: 0.3549 - val_accuracy: 0.9135\n",
      "Epoch 7/100\n",
      "1220/1229 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8114\n",
      "Epoch 00007: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4678 - accuracy: 0.8113 - val_loss: 0.3281 - val_accuracy: 0.9143\n",
      "Epoch 8/100\n",
      "1223/1229 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.8118\n",
      "Epoch 00008: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4665 - accuracy: 0.8118 - val_loss: 0.3206 - val_accuracy: 0.9141\n",
      "Epoch 9/100\n",
      "1218/1229 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8130\n",
      "Epoch 00009: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 4s 3ms/step - loss: 0.4643 - accuracy: 0.8129 - val_loss: 0.3313 - val_accuracy: 0.9139\n",
      "Epoch 10/100\n",
      "1217/1229 [============================>.] - ETA: 0s - loss: 0.4643 - accuracy: 0.8123\n",
      "Epoch 00010: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4643 - accuracy: 0.8124 - val_loss: 0.3462 - val_accuracy: 0.9122\n",
      "Epoch 11/100\n",
      "1223/1229 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.8127\n",
      "Epoch 00011: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4625 - accuracy: 0.8128 - val_loss: 0.3242 - val_accuracy: 0.9124\n",
      "Epoch 12/100\n",
      "1219/1229 [============================>.] - ETA: 0s - loss: 0.4630 - accuracy: 0.8127\n",
      "Epoch 00012: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4628 - accuracy: 0.8129 - val_loss: 0.3139 - val_accuracy: 0.9122\n",
      "Epoch 13/100\n",
      "1228/1229 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8131\n",
      "Epoch 00013: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4621 - accuracy: 0.8130 - val_loss: 0.3398 - val_accuracy: 0.9119\n",
      "Epoch 14/100\n",
      "1228/1229 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8128\n",
      "Epoch 00014: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4619 - accuracy: 0.8128 - val_loss: 0.3338 - val_accuracy: 0.9124\n",
      "Epoch 15/100\n",
      "1225/1229 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.8128\n",
      "Epoch 00015: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 4s 3ms/step - loss: 0.4596 - accuracy: 0.8129 - val_loss: 0.3345 - val_accuracy: 0.9122\n",
      "Epoch 16/100\n",
      "1227/1229 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.8127\n",
      "Epoch 00016: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 4s 3ms/step - loss: 0.4595 - accuracy: 0.8128 - val_loss: 0.3328 - val_accuracy: 0.9135\n",
      "Epoch 17/100\n",
      "1228/1229 [============================>.] - ETA: 0s - loss: 0.4587 - accuracy: 0.8131\n",
      "Epoch 00017: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4588 - accuracy: 0.8131 - val_loss: 0.3272 - val_accuracy: 0.9118\n",
      "Epoch 18/100\n",
      "1220/1229 [============================>.] - ETA: 0s - loss: 0.4582 - accuracy: 0.8130\n",
      "Epoch 00018: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4582 - accuracy: 0.8131 - val_loss: 0.3328 - val_accuracy: 0.9147\n",
      "Epoch 19/100\n",
      "1227/1229 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8137\n",
      "Epoch 00019: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4579 - accuracy: 0.8136 - val_loss: 0.3240 - val_accuracy: 0.9146\n",
      "Epoch 20/100\n",
      "1228/1229 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.8142\n",
      "Epoch 00020: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4573 - accuracy: 0.8142 - val_loss: 0.3460 - val_accuracy: 0.9133\n",
      "Epoch 21/100\n",
      "1223/1229 [============================>.] - ETA: 0s - loss: 0.4580 - accuracy: 0.8136\n",
      "Epoch 00021: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 5s 4ms/step - loss: 0.4582 - accuracy: 0.8136 - val_loss: 0.3262 - val_accuracy: 0.9132\n",
      "Epoch 22/100\n",
      "1224/1229 [============================>.] - ETA: 0s - loss: 0.4561 - accuracy: 0.8140\n",
      "Epoch 00022: val_accuracy did not improve from 0.91654\n",
      "1229/1229 [==============================] - 6s 5ms/step - loss: 0.4561 - accuracy: 0.8141 - val_loss: 0.3300 - val_accuracy: 0.9151\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using training data with validation using a subset of the test data\n",
    "model_train_data = model.fit(obs, results, validation_data=(validation_obs, validation_res), epochs=100, batch_size=32, shuffle=True, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35543423891067505, 0.9164345264434814]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Best Model Weights and Evaluate Model on entire test set\n",
    "model.load_weights(\"icu.h5\") \n",
    "model.evaluate(test[features], test['icu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.9163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3556526005268097, 0.9163327217102051]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Model on subset of test set\n",
    "model.evaluate(test_obs, test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.95848161 0.5096505 ]\n",
      "Recall: [0.94977559 0.55924442]\n",
      "F-Score: [0.95410874 0.53329694]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score metrics for entire test set\n",
    "preds = model.predict(test[features])\n",
    "labels = []\n",
    "for pred in preds[:, 0]:\n",
    "    if pred > 0.5:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "metrics = precision_recall_fscore_support(test['icu'], labels)\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.95917045 0.50873587]\n",
      "Recall: [0.94892071 0.56701031]\n",
      "F-Score: [0.95401805 0.53629469]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score metrics for subset of test set\n",
    "preds = model.predict(test_obs)\n",
    "labels_test = []\n",
    "for pred in preds[:, 0]:\n",
    "    if pred > 0.5:\n",
    "        labels_test.append(1)\n",
    "    else:\n",
    "        labels_test.append(0)\n",
    "metrics = precision_recall_fscore_support(test_res, labels_test)\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lethality Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220657, 21)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form dataset with only death status known\n",
    "lethal_res_known = covid_cases[covid_cases['lethal'] != -1]\n",
    "lethal_res_known.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form train test\n",
    "train, test = train_test_split(lethal_res_known, shuffle=True, test_size=0.3, stratify=lethal_res_known['lethal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Balanced returning sampled dataet.\n"
     ]
    }
   ],
   "source": [
    "# Check if the resutls are balanced and get obs, results which are balanced\n",
    "obs, results = checkBinaryBalance(train, features, 'lethal', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8412942989214176\n",
      "Precision: [0.97676144 0.4274075 ]\n",
      "Recall: [0.83901691 0.85754671]\n",
      "F-Score: [0.90266454 0.57048242]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest on training from the sampled dataset\n",
    "randomForestEvaluation(obs, results, test[features], test['lethal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8936070576150337\n",
      "Precision: [0.91212821 0.62706347]\n",
      "Recall: [0.97237436 0.33148968]\n",
      "F-Score: [0.94128827 0.43370588]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Rnadom forest on training form the original dataset\n",
    "randomForestEvaluation(train[features], train['lethal'], test[features], test['lethal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Balanced returning sampled dataet.\n",
      "Training Decision Tree\n",
      "Train Accuracy: 0.9516838082115382\n",
      "Train Precision: [0.95584981 0.9429023 ]\n",
      "Train Recall: [0.9724423  0.91016682]\n",
      "Train F-Score: [0.96407467 0.92624541]\n",
      "\n",
      "Test Accuracy: 0.8577147345841264\n",
      "Test Precision: [0.93176049 0.4349853 ]\n",
      "Test Recall: [0.90398195 0.52753196]\n",
      "Test F-Score: [0.91766105 0.47680942]\n",
      "-----------\n",
      "Training Random Forest\n",
      "Train Accuracy: 0.9504289487065926\n",
      "Train Precision: [0.96543277 0.92092073]\n",
      "Train Recall: [0.96001673 0.93125338]\n",
      "Train F-Score: [0.96271713 0.92605823]\n",
      "\n",
      "Test Accuracy: 0.8602223632133902\n",
      "Test Precision: [0.94354883 0.45003131]\n",
      "Test Recall: [0.89413041 0.61823992]\n",
      "Test F-Score: [0.91817515 0.52089266]\n",
      "-----------\n",
      "Training Neural Net\n",
      "Train Accuracy: 0.8514590817381035\n",
      "Train Precision: [0.92673503 0.73515353]\n",
      "Train Recall: [0.84390532 0.86656661]\n",
      "Train F-Score: [0.88338281 0.79546918]\n",
      "\n",
      "Test Accuracy: 0.8441946886612889\n",
      "Test Precision: [0.97627977 0.43224241]\n",
      "Test Recall: [0.84284041 0.85385939]\n",
      "Test F-Score: [0.90466595 0.5739425 ]\n",
      "-----------\n",
      "Training AdaBoost\n",
      "Train Accuracy: 0.8399931105752669\n",
      "Train Precision: [0.88845849 0.74913352]\n",
      "Train Recall: [0.86910093 0.78177747]\n",
      "Train F-Score: [0.87867311 0.76510746]\n",
      "\n",
      "Test Accuracy: 0.8582887700534759\n",
      "Test Precision: [0.96427413 0.45479631]\n",
      "Test Recall: [0.87068995 0.76978859]\n",
      "Test F-Score: [0.91509562 0.57178071]\n",
      "-----------\n",
      "Training Naive Bayes\n",
      "Train Accuracy: 0.8149041221724652\n",
      "Train Precision: [0.89663325 0.68863238]\n",
      "Train Recall: [0.81648295 0.81174647]\n",
      "Train F-Score: [0.85468313 0.74513834]\n",
      "\n",
      "Test Accuracy: 0.8174718269434121\n",
      "Test Precision: [0.97045041 0.3861289 ]\n",
      "Test Recall: [0.81676484 0.82251721]\n",
      "Test F-Score: [0.88699978 0.52554286]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models for \"lethal\"\n",
    "# Form train test\n",
    "train, test = train_test_split(lethal_res_known, shuffle=True, test_size=0.3, stratify=lethal_res_known['lethal'])\n",
    "# Check if the resutls are balanced and get obs, results which are balanced\n",
    "obs, results = checkBinaryBalance(train, features, 'lethal', 0, 1)\n",
    "sampled_lethal_scores = allModelEvaluation(names, classifiers, obs, results, test[features], test['lethal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8975223574255974\n",
      "Precision: [0.42052679 0.9550408 ]\n",
      "Recall: [0.53005152 0.93182304]\n",
      "F-Score: [0.46897949 0.94328907]\n"
     ]
    }
   ],
   "source": [
    "# Based on the above results we can gauge that _____ is the best model. So let us try running hyperparemeter optimization on it\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "calibrated_forest = CalibratedClassifierCV(\n",
    "   base_estimator=RandomForestClassifier())\n",
    "param_grid = {\n",
    "   'base_estimator__max_depth': [20, 40, 60, 80, 100, 120],\n",
    "    'base_estimator__n_estimators': [10, 50, 100, 150, 200]}\n",
    "search = GridSearchCV(calibrated_forest, param_grid, cv=5)\n",
    "search.fit(obs, results)\n",
    "\n",
    "print(\"Accuracy: {}\".format(search.score(test[features], test['lethal'])))\n",
    "metrics = precision_recall_fscore_support(test['lethal'], search.predict(test[features]))\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,777\n",
      "Trainable params: 3,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a Fully Connected Model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_dim=17))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpoints\n",
    "# Callback to Early Stop if Validation loss is not improving\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "# Callback to Keep storing best model\n",
    "mc = ModelCheckpoint(\"lethal.h5\", monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obs, validation_obs, test_res, validation_res = train_test_split(test[features], test['lethal'], test_size=0.5, shuffle=True, stratify=test['lethal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3767/3811 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.8368\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83546, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 3s 912us/step - loss: 0.3509 - accuracy: 0.8371 - val_loss: 0.2874 - val_accuracy: 0.8355\n",
      "Epoch 2/100\n",
      "3793/3811 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.8460\n",
      "Epoch 00002: val_accuracy improved from 0.83546 to 0.83595, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 3s 891us/step - loss: 0.3345 - accuracy: 0.8460 - val_loss: 0.2902 - val_accuracy: 0.8359\n",
      "Epoch 3/100\n",
      "3767/3811 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.8457\n",
      "Epoch 00003: val_accuracy improved from 0.83595 to 0.83936, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 3s 895us/step - loss: 0.3328 - accuracy: 0.8457 - val_loss: 0.2824 - val_accuracy: 0.8394\n",
      "Epoch 4/100\n",
      "3793/3811 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.8466\n",
      "Epoch 00004: val_accuracy improved from 0.83936 to 0.84474, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 4s 955us/step - loss: 0.3317 - accuracy: 0.8465 - val_loss: 0.2758 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "3762/3811 [============================>.] - ETA: 0s - loss: 0.3310 - accuracy: 0.8466\n",
      "Epoch 00005: val_accuracy did not improve from 0.84474\n",
      "3811/3811 [==============================] - 3s 898us/step - loss: 0.3312 - accuracy: 0.8465 - val_loss: 0.2794 - val_accuracy: 0.8403\n",
      "Epoch 6/100\n",
      "3767/3811 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.8469\n",
      "Epoch 00006: val_accuracy improved from 0.84474 to 0.84616, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 3s 880us/step - loss: 0.3306 - accuracy: 0.8468 - val_loss: 0.2754 - val_accuracy: 0.8462\n",
      "Epoch 7/100\n",
      "3783/3811 [============================>.] - ETA: 0s - loss: 0.3302 - accuracy: 0.8464\n",
      "Epoch 00007: val_accuracy improved from 0.84616 to 0.85604, saving model to lethal.h5\n",
      "3811/3811 [==============================] - 4s 935us/step - loss: 0.3303 - accuracy: 0.8464 - val_loss: 0.2613 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "3800/3811 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8472\n",
      "Epoch 00008: val_accuracy did not improve from 0.85604\n",
      "3811/3811 [==============================] - 4s 928us/step - loss: 0.3293 - accuracy: 0.8471 - val_loss: 0.2643 - val_accuracy: 0.8547\n",
      "Epoch 9/100\n",
      "3806/3811 [============================>.] - ETA: 0s - loss: 0.3291 - accuracy: 0.8472\n",
      "Epoch 00009: val_accuracy did not improve from 0.85604\n",
      "3811/3811 [==============================] - 4s 953us/step - loss: 0.3291 - accuracy: 0.8472 - val_loss: 0.2760 - val_accuracy: 0.8389\n",
      "Epoch 10/100\n",
      "3794/3811 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8469\n",
      "Epoch 00010: val_accuracy did not improve from 0.85604\n",
      "3811/3811 [==============================] - 3s 910us/step - loss: 0.3292 - accuracy: 0.8469 - val_loss: 0.2668 - val_accuracy: 0.8477\n",
      "Epoch 11/100\n",
      "3808/3811 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.8480\n",
      "Epoch 00011: val_accuracy did not improve from 0.85604\n",
      "3811/3811 [==============================] - 3s 895us/step - loss: 0.3288 - accuracy: 0.8480 - val_loss: 0.2677 - val_accuracy: 0.8475\n",
      "Epoch 12/100\n",
      " 262/3811 [=>............................] - ETA: 2s - loss: 0.3280 - accuracy: 0.8508"
     ]
    }
   ],
   "source": [
    "# Fit the model using training data with validation using a subset of the test data\n",
    "model_train_data = model.fit(obs, results, validation_data=(validation_obs, validation_res), epochs=100, batch_size=32, shuffle=True, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Model Weights and Evaluate Model on entire test set\n",
    "model.load_weights(\"lethal.h5\") \n",
    "model.evaluate(test[features], test[\"lethal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on subset of test set\n",
    "model.evaluate(test_obs, test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.95668995 0.50782515]\n",
      "Recall: [0.95127164 0.53863766]\n",
      "F-Score: [0.9539731  0.52277778]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score metrics for entire test set\n",
    "preds = model.predict(test[features])\n",
    "labels = []\n",
    "for pred in preds[:, 0]:\n",
    "    if pred > 0.5:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "metrics = precision_recall_fscore_support(test_results, labels)\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.95713825 0.51409978]\n",
      "Recall: [0.95212652 0.54295533]\n",
      "F-Score: [0.95462581 0.5281337 ]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score metrics for subset of test set\n",
    "preds = model.predict(test_obs)\n",
    "labels_test = []\n",
    "for pred in preds[:, 0]:\n",
    "    if pred > 0.5:\n",
    "        labels_test.append(1)\n",
    "    else:\n",
    "        labels_test.append(0)\n",
    "metrics = precision_recall_fscore_support(test_res, labels_test)\n",
    "print(\"Precision: {}\\nRecall: {}\\nF-Score: {}\".format(metrics[0], metrics[1], metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
